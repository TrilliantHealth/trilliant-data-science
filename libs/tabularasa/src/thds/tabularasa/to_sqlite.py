"""Helpers for taking an in-memory set of Tables and writing them to a
SQLite database file without needing to go through a build process.
"""

import os
import typing as ty
from pathlib import Path

from .data_dependencies.sqlite import populate_sqlite_db
from .schema.metaschema import BuildOptions, Schema, Table

FAKE_BUILD_OPTIONS = BuildOptions(
    derived_code_submodule="thds.nope",
    attrs=False,
    sqlite_data=True,
    sqlite_interface=False,
    pandas=False,
    pyarrow=False,
    require_typing_extensions=False,
    type_constraint_comments=False,
    validate_transient_tables=False,
)


def _make_fake_schema(tables: ty.Collection[Table]) -> Schema:
    return Schema(
        tables={table.name: table for table in tables},
        types=dict(),
        # none of the build options are actually relevant to us.
        build_options=FAKE_BUILD_OPTIONS,
    )


def to_sqlite(sqlite_file_path: Path, *tables: Table, **data_paths_by_table_name: Path) -> None:
    """Create a SQLite database file from the given Tables alone.

    The data_paths_by_table_name are only required if your Table
    instances do not provide a file path to their data via the `doc`
    attribute. Tables generated by define_table_from_parquet will
    follow this convention.
    """
    populate_sqlite_db(
        _make_fake_schema(tables),
        None,
        str(sqlite_file_path),
        None,
        "",
        "",
        table_predicate=lambda table: True,  # output all tables.
        data_path_overrides={
            table.name: (
                Path(table.doc) if os.path.exists(table.doc) else data_paths_by_table_name[table.name]
            )
            for table in tables
        },
    )
