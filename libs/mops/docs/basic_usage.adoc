link:../README.adoc[â†‘]

# Basic usage

You'll decorate your function with `@pure.magic`, passing a
link:shims.adoc[`runtime shim`] to transfer the execution to the remote environment.

## execution environment

`thds.mops` must be installed both in the local environment and the remote environment.

On the link:orchestrator.adoc[orchestrator], you will need to install the dependencies
required for importing your function. If your function can be imported and the arguments
to it constructed, `mops` will kick in and prevent the function itself from being called
on the local machine.  A common pattern is to defer environment-specific imports (such as
`pyspark`) to the inside of the function. You might want to split the bulk of the function into a separate module,
and import that module within the `+mops+`-wrapped function, e.g.:

[source,python]
----
@pure.magic()
def foobar(*args, **kwargs):
    from . import internal

    return internal.foobar(*args, **kwargs)
----
NOTE: The above is an abbreviated example; we do not recommend using `*args, **kwargs`,
which lowers code readability.

On the link:remote.adoc[remote(s)], you will need to install `mops` and all dependencies
required for importing the function as well as executing it.

In practice, the simplest way to do this will often be to package the entire Python
application and install it on the remote,footnote:[Often, a good way to do this will be to
have a single Docker image or wheel that contains the full application and is used
for/installed on both the orchestrator and the remote(s).] even though only a part of
it will actually be executed.


## Transfer of control to the remote via a runtime shim

To use ``pure.magic``/``MemoizingPicklingRunner``, you need to choose a
link:./shims.adoc[`runtime shim`] implementation and environment. The best choice will
often be Python running in a Docker container spawned by link:kubernetes.adoc[Kubernetes],
but as demonstrated by link:fibonacci.py[], it is also possible to use something as simple
as running in the same thread. Your runtime shim simply needs to begin execution of a
Python process in an environment, running `mops` remote `+__main__+` with the string
arguments provided to it.

Once you have selected a `runtime shim`, you will need to wrap your function with a
`MemoizingPicklingRunner` that can use or instantiate that `runtime shim`.

[source,python]
----
import typing as ty

from thds.mops import pure, k8s

IMAGE_TAG: ty.Final = "docker.io/myimage:latest"
MOPS_ROOT_URI: ty.Final = "adls://yoursa/container/"

run_on_k8s = k8s.shim(
    IMAGE_TAG,
    node_narrowing=dict(resource_requests=dict(memory='120G'))
)

@pure.magic(run_on_k8s, blob_root=MOPS_ROOT_URI)
def my_resource_intensive_function(model: pd.DataFrame, rounds: int) -> pd.DataFrame:
    ... # do some stuff, return a dataframe

if __name__ == '__main__':
    # now, call your function locally and it will be run remotely
    df = my_resource_intensive_function(the_model_df, 15)
    assert type(df) == pd.DataFrame
    # `df` is your result, computed on and transferred back from the remote context
----

Now you run your application locally, and your functions will be called remotely and their results will
be returned to you. Your local process can call `@pure.magic`-decorated functions in threads or even
separate processes, though threads are your best bet for the large majority of scenarios.

## Output locations

`mops` has several link:optimizations.adoc[optimizations] to help with the overhead of transferring work to and from remote runners. The one you'll need most often is a representation of large input and output data.

* When defining a location for large output data that is a single file, use
  `thds.core.source.from_file` to create a `Source` object. `Source` is an `os.PathLike`,
  and it is heavily optimized by `mops`. It will receive an autogenerated, unique remote
  path when it is created.footnote:[`source.from_file` will work transparently even if you
  completely disable your use of `mops`.]

* `Source` objects can be be passed transparently and efficiently _into_ `mops`-wrapped
  functions as well - the local process will not download the file if it is not opened
  locally. It's a good practice to define your blob input parameters as `Source` if at all
  possible.

* If you need an output location that is a directory, use
  `pure.adls.invocation_output_fqn(name='foobar')` - as with `source.from_file`, the
  storage root will be automatically derived from the root of your mops execution
  context.footnote:[The `invocation_output_fqn` directory approach does _not_ work
  transparently if you remove `mops` - if you have a need for directories to be supported
  transparently in local and remote use cases, let's talk!]

## Runner bypass

NOTE: This documentation is still correct, but an improved API is available via link:magic.adoc#off[`pure.magic.off()`], and we recommend you use that.

`mops` has been carefully designed to allow you to integrate it with your existing code with a
minimum of changes. This includes the ability to directly call the functions you're integrating with
`mops` while bypassing all use of `mops`.

Because Python is a very dynamic language, you have many options for how to implement this in your own
application. For highly dynamic cases, your best bet may be to write your own application logic to
conditionally apply the decorator to functions that you do or do not want to run remotely at runtime.

However, for all-or-nothing cases, such as local test runs of a pipeline designed to be run remotely,
your application may simply pass `skip_runner=True` to the `use_runner` decorator factory wherever you
are using it, and all calls via that decorator will be directly passed to the implementing function
without further ceremony.

- `skip_runner` may also be any parameterless callable returning a `bool` in order to make this easy to
  configure at runtime, e.g. `lambda: bool(os.getenv('YOUR_APP_NO_REMOTE'))`.
