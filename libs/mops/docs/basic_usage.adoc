link:../README.adoc[â†‘]

# Basic usage

You'll decorate your function with `use_runner`, which requires a `MemoizingPicklingRunner` instance,
which itself requires a `Shell` to transfer the execution to the remote environment.

## execution environment

`thds.mops` must be installed both in the local environment and the remote environment.

On the link:orchestrator.adoc[orchestrator], you will need to have _all_ dependencies available, or at least
everything that your orchestrator needs to be able to import using Python, as though it were going to run
the entire program locally.

On the link:remote.adoc[remote(s)], you only need to have `mops` and the dependencies for the specific
function that the remote will be responsible for executing. In practice, the simplest way to do this will
often be to package the entire Python application and install it on the remote, even though only a part
of it will actually be executed.

Often, a good way to do this will be to have a single Docker image or wheel that contains the full
application and is used for/installed on both the orchestrator and the remote(s).

## Transfer of control to the remote via a Shell

To use a `MemoizingPicklingRunner`, you need to choose a `Shell` implementation and environment. The best
choice will often be Python running in a Docker container spawned by link:kubernetes.adoc[Kubernetes], but
as demonstrated by link:fibonacci.py[], it is also possible to substitute something as simple as `subprocess.run`. Your shell simply needs to begin execution of a Python application in an environment where the `mops` remote `+__main__+` can begin executing immediately.

Once you have selected a `Shell`, you will need to wrap your function with a
`MemoizingPicklingRunner` that can use or instantiate that `Shell`.

[source,python]
----
import typing as ty

from thds.mops import pure
from thds.mops import k8s

IMAGE_TAG: ty.Final = "docker.io/myimage:latest"
MOPS_ROOT_URI: ty.Final = "adls://yoursa/container/"

run_on_k8s = pure.use_runner(
    pure.MemoizingPicklingRunner(
        k8s.mops_shell(
            IMAGE_TAG,
            node_narrowing=dict(resource_requests=dict(memory='120G'))
        ),
        MOPS_ROOT_URI,
    )
)
# ^ a decorator that can now cause any pure function to be run remotely on K8s...

@run_on_k8s
def my_resource_intensive_function(model: pd.DataFrame, rounds: int) -> pd.DataFrame:
    ... # do some stuff, return a dataframe

if __name__ == '__main__':
    # now, call your function locally and it will be run remotely
    df = my_resource_intensive_function(the_model_df, 15)
    assert type(df) == pd.DataFrame
    # `df` is your result, computed on and transferred back from the remote context
----

Now you run your application locally, and your functions will be called remotely and their results will
be returned to you. Your local process can call `use_runner`-decorated functions in threads or even
separate processes, though threads are your best bet for the large majority of scenarios.

## Output locations

`mops` has several link:optimizations.adoc[optimizations] to help with the overhead of transferring work to and from remote runners. The one you'll need most often is a representation of large input and output data.

* When defining a location for large output data that is a single file, use `thds.core.source.from_file` to create a `Source` object. `Source` is an `os.PathLike`, and it is heavily optimized by `mops`. It will receive an autogenerated, unique remote path when it is created.footnote:[`source.from_file` will work transparently even if you completely disable your use of `mops`.]

* `Source` objects can be be passed transparently and efficiently _into_ `mops`-wrapped functions as well - the local process will not download the file if it is not opened locally. It's a good practice to define your blob input parameters as `Source` if at all possible.

* If you need an output location that is a directory, use `pure.adls.invocation_output_fqn(name='foobar')` - as with `source.from_file`, the storage root will be automatically derived from the root
of your mops execution context.footnote:[The `invocation_output_fqn` directory approach does _not_ work transparently if you remove `mops` - if you have a need for directories to be supported transparently in local and remote use cases, let's talk!]

## Runner bypass

`mops` has been carefully designed to allow you to integrate it with your existing code with a
minimum of changes. This includes the ability to directly call the functions you're integrating with
`mops` while bypassing all use of `mops`.

Because Python is a very dynamic language, you have many options for how to implement this in your own
application. For highly dynamic cases, your best bet may be to write your own application logic to
conditionally apply the decorator to functions that you do or do not want to run remotely at runtime.

However, for all-or-nothing cases, such as local test runs of a pipeline designed to be run remotely,
your application may simply pass `skip_runner=True` to the `use_runner` decorator factory wherever you
are using it, and all calls via that decorator will be directly passed to the implementing function
without further ceremony.

- `skip_runner` may also be any parameterless callable returning a `bool` in order to make this easy to
  configure at runtime, e.g. `lambda: bool(os.getenv('YOUR_APP_NO_REMOTE'))`.
