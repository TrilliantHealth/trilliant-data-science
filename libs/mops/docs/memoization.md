# Memoization/caching

A [pure function](./pure_functions.md) is by definition a fully-specified computation with a
deterministic result based on its arguments. If the function and its arguments remain the same, then a
future call to that function, even from a different process on a different computer, should be able to
return the previously-computed result rather than re-computing.

One scenario where this might be useful would be in the case of some kind of failure of your long-running
orchestrator process. Another scenario would be explicitly opting in to results that you know someone
else has already computed.

## in `mops`:

Each `use_runner`-decorated function using `mops` `MemoizingPicklingRunner` will combine the
current\[^1\] `pipeline_id`, the fully-qualfied name (including module) of the function, and the hash of
the serialized arguments to the function, to produce a _deterministic_ remote storage location for the
invocation and also for the eventual results.

> \[^1\]: **By default**, a new pipeline id is generated by mops for every orchestrator process that does
> not specify a `pipeline_id`, which means that without additional specification by the code author,
> results will not get reused by default.

_Before_ invoking the function remotely, the `MemoizingPicklingRunner` will check to see if a result
already exists at the expected path, and if it does, that result will be returned _instead_ of running
the remote computation.

This allows function results to be reused across time regardless of who calls the function or when they
call it.

In cases where all you want is memoization (you don't care about transferring execution to a truly
[remote execution environment](./remote.md)), you may be able to use `pure.memoize_in` as a shorthand,
rather than needing to define a `MemoizingPicklingRunner` yourself.

In [advanced use cases](./advanced_memoization.md), you may want to memoize on something other than the
actual function arguments.

## Memoization specification

At a conceptual level, memoized results are stored under a determinstic hash of the function
`(args, kwargs)`, within a _memospace_ that is derived from the application context and function at the
time of its call. This memospace is fundamentally a fully-qualified (atomic) namespace, but in
implementation it is derived from 3 'logical' pieces:

1. A storage root provided by your top-level configuration, plus a `mops`-specific suffix, making up a
   runner prefix that is the global default for any `mops.use_runner` decorated function in your
   application.

1. The `pipeline_id`. It can be set globally by the application, but a unique default is generated upon
   the first call to a `mops` `use_runner` function if one has not already been set. `pipeline_id` may
   also be masked via the `pipeline_id_mask` decorator and context manager, applied _over top_ of the
   `use_runner` decorator.

   You may conceptualize the pipeline id as representing a static codebase; if your code does not change,
   there is no reason to change the pipeline id. A future version of `mops` may rename this concept to
   better communicate its intended semantics.

1. A `function_id`, derived from the `use_runner`-decorated function module+name. This exists to keep
   identical `(*args, **kwargs)` separate from each other if passed to different functions.

The function author is fully (and trivially) in control of the `function id` component, but the
application that calls the function is encouraged to globally set and/or locally mask the `pipeline id`.
Generally, the `storage root` will be set differently via configuration for production vs development,
but will be shared across the application run.

This is an example full `memo_uri` with all its constituent parts labeled. You'll find most of these
names directly [in the source code](../src/thds/mops/pure/core/memo/function_memospace.py). For
memoization to retrieve an existing result, the _full_ constructed memo uri must be retrievable from the
provided storage system.

```
adls://thdsscratch/tmp/mops2-mpf/Peter-Gaultney/2023-04-12T15:46:24-p36529/demandforecast.extract:extract_asset_geo_level/CoastOilAsset.IVZ9KplQKlNgxQHav0jIMUS9p4Kbn3N481e0Uvs/
<storage root ------->
<runner prefix ----------------> <pipeline_id ---------------------------> <function_id --------------------------------> <(args, kwargs) sha256 hash ------------------------>
<pipeline memospace ----------------------------------------------------->
<function memospace ---------------------------------------------------------------------------------------------------->
                                <invocation-unique-key ----------------------------------------------------------------------------------------------------------------------->
<memo uri -------------------------------------------------------------------------------------------------------------------------------------------------------------------->
```

Note that the `invocation-unique-key` is a way of uniquely identifying a function invocation solely by
reference to the user-controllable, storage-agnostic elements of the `memo_uri`.

Therefore:

If you want to call a function and get a result that you know already exists (was previously already run
and therefore memoized by `MemoizingPicklingRunner`), you have three main options. These options are
listed in reverse priority order - the more specific options (listed further down) will be checked first,
and if configured, the less-specific options (listed earlier) will not be attempted.

> ðŸš¨ In all cases, it's very important to understand that whether or not memoized results are available
> within the namespace as specified or derived will _not_ prevent _new, unmemoized_ results from being
> computed and inserted into that same namespace.
>
> In other words, no error will be raised if the result is not already present. This is a
> **non-destructive** re-use of the namespace, because no existing results will be modified in any way -
> but an existing namespace is never immune to **modification** if provided to `mops`.

### global pipeline id with global storage root

> Operation: global, via dict config or set globally by the application.

The global option is to set up your application to run identically to the run that generated the result.
This includes making sure that the [configured value](./config.md) for `mops.memo.storage_root` is the
same as from that known run, and then calling `set_pipeline_id` with the `pipeline_id` used or generated
by the known run.

This global option is most suitable for cases where your application ran partway and then died for some
reason. Re-using the same config including `pipeline_id` will allow you to just pick up where you left
off.

The simplest way to set the global pipeline id is by calling
`thds.mops.pure:set_pipeline_id('yourpipeid')` in the CLI of your application. Be aware that this is a
global call that must be performed before calling any `mops`-decorated functions.

### pipeline id mask with global storage root

> Operation: global storage root, plus stack-local pipeline id mask set by the application or library via
> decorator or context manager.

You may decorate any `use_runner`-decorated function with `thds.mops.pure.pipeline_id_mask`. It _must_ be
applied outside the `use_runner` decorator, because it will set a stack-local variable at the time of
invocation of the function, but prior to the operation of the underlying `Runner` that will reference its
work.

> A pipeline id mask will in all cases override the global pipeline id.

It may also be used as a context manager, with the caveat that this will _not_ propagate to threads
created in the current context.

> â˜ ï¸ â˜ ï¸ â˜ ï¸ Logically, the 'pipeline id mask' for a given function changes every time the function code
> changes. If you use this as a decorator directly on a `use_runner` function, and fail to change its
> string value after the underlying code has changed, then your function's callers will get **unwanted**
> memoization. **YOU HAVE BEEN WARNED.**

```python
# every call to this function will automatically use the below pipeline_id.
# The decorator will always apply regardless of threading.

@pipeline_id_mask('2023-05-02')
@use_runner(MemoizingPicklingRunner(...))
def generate_nppes(...):
    ...

@pipeline_id_mask('other')
@use_runner(MemoizingPicklingRunner(...))
def use_nppes(...):
    ...

# however, if a caller wishes to override, they have several options:

# option 1, as context manager
# suitable for call only in the _current_ thread/process:
with pipeline_id_mask('special-run'):
    nppes = generate_nppes(...)
    use_nppes(nppes)
    # note that both mops functions will use this same pipeline id mask.

# option 2, suitable for calling the function in a separate thread later on...
my_special_nppes = pipeline_id_mask('special-run')(generate_nppes)
...
nppes = my_special_nppes(...)
# but the undecorated `use_nppes` will use its own mask
use_nppes(nppes)

# option 3, also suitable for use in a launched thread:
@pipeline_id_mask('special-run')
def my_special_nppes(*args, **kwargs):
    args, kwargs = special_adjust_args_kwargs(args, kwargs)
    return generate_nppes(*args, **kwargs)
...
my_special_nppes(...)
```

As seen above, this decorator or its underlying context manager may even be applied multiple times -
_only_ the outermost call to this decorator will be applied at the time of function invocation, providing
the final say to the calling application.

### function-scoped fully-qualified memospace

> Operation: per-function (referenced by function_id) memospace, set by application via global (TOML) or
> stack-local (context manager) config.

The most direct option is to configure, on a per-memoized/decorated function basis, the fully-qualified
`memospace` from the known run, referenced by the fully-qualified name of the function at its _current
location_.

> This approach overrides **both** of the previous approaches, and differs from them in that any
> globally-configured storage root will be overridden by this fully-qualified function memospace.

You might use this option if the function in question has been renamed and/or moved to a different module
since the results were memoized, or if you know an exact location where previous results exist and you
want to hard-code that result set outside of your code. This renaming ability affords the most direct
control compared to the other options for configuring memoization.

In the following example, function `foo` was previously run with `pipeline_id=2023april`, and the results
were stored on `thdsdatasets/ml-ops`. The run which will re-use these results will have an autogenerated
`pipeline_id` and will use the configured values for SA and container for all of the other,
not-configured functions.

In a complete mops [config file](./config.md), add the following lines to your config:

```toml
[mops.memo."thds.mymodule.foomod:foobar"]
memospace = "adls://thdsdatasets/ml-ops/mops/pipeline-pickled-functions-v1/2023april/thds.mymodule.OLDMOD:barbaz"
```

Note that the name that is part of the configuration key must be the fully-qualified path to the function
in the _current_ codebase. This is how we will recognize what results you're trying to retrieve when you
call the current function.

The `memospace`, however, is a fully-qualified ADLS URI that actually exists and was created by the
previous run that you're trying to reuse. Note that to find this, you need to know three core components
from the previous run:

1. The URI that was configured as `mops.memo.storage_root`.
1. The `pipeline_id` that was in use.
1. The fully qualified `module:function_name` at the time of the run.

> âš ï¸ This configuration needs to be present every time a memoized result is retrieved. You cannot perform
> a new run with this config, and then expect a future reuse of the _new_ pipeline id to present you with
> those results. They will not be found.
>
> In other words, this configuration is cumulative and explicit - if you want to pick up results from
> various different historical runs, you'll need to specify the configuration for each previous run.
