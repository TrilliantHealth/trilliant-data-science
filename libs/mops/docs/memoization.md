# Memoization/caching

A [pure function](./pure_functions.md) is by definition a
fully-specified computation with a deterministic result based on its
arguments. If the function and its arguments remain the same, then a
future call to that function, even from a different process on a
different computer, should be able to return the previously-computed
result rather than re-computing.

## in `mops`:

Each `pure_remote`-decorated function using `mops` `PickleRunner` will
combine the current `pipeline_id`, the fully-qualfied name (including
module) of the function, and the hash of the serialized arguments to
the function, to produce a _deterministic_ remote storage location for
the invocation and also for the eventual results.

Then, _before_ invoking the function remotely, the `PickleRunner` will check
to see if a result already exists at the expected path, and if it
does, that result will be returned _instead_ of running the remote
computation.

This allows function results to be reused across time regardless of
who calls the function or when they call it.

One scenario where this might be useful would be in the case of some
kind of failure of your long-running orchestrator process. Another
scenario would be explicitly opting in to results that you know
someone else has already computed.

## Memoization configuration

At a conceptual level, memoized results are stored under a
determinstic hash of the function `(args, kwargs)`, within a
_memospace_ that is derived from the application context and function
at the time of its call. This memospace is fundamentally a
fully-qualified (atomic) namespace, but in implementation it is
derived from 3 'logical' pieces:

1. A storage root provided by your top-level configuration, plus a
   `mops`-specific suffix, making up a runner prefix that is the
   global default for an application run using `mops`.
2. The `pipeline_id`, either generated by mops or set by the application.
3. A `function_id`, derived from the decorated function module+name
   and, optionally, `@<function-logic-key>`, which is extracted (if
   present) from the function's docstring.

The function author is fully in control of the third component, but
the author of the application that calls the function is fundamentally
in control of the second, and of the first to a lesser extent.

This is an example full `memo_uri` with all its constituent parts
labeled. You'll find most of these names directly
[in the source code](../src/thds/mops/remote/_memoize.py).

```
adls://thdsscratch/tmp/mops/pipeline-pickled-functions-v1/Peter-Gaultney/2023-04-12T15:46:24-p36529/demandforecast.extract:extract_asset_geo_level@2023april18-ganderson/1/82e81dbaa7fc3c7d264aff80130f955c802523bc3d9764a261e256caf7debc7
<storage root ------->
<runner prefix -----------------------------------------> <pipeline_id ---------------------------> <function module:name -----------------------> <function-logic-key > <(args, kwargs) sha256 hash ------------------------------------>
                                                                                                    <function id ------------------------------------------------------>
<function memospace --------------------------------------------------------------------------------------------------------------------------------------------------->
                                                          <invocation-unique-key -------------------------------------------------------------------------------------------------------------------------------------------------------->
<memo uri ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------->
```

Note that the `invocation-unique-key` is a way of uniquely identifying
a function invocation solely by reference to the user-controllable,
storage-agnostic elements of the `memo_uri`.

Therefore:

If you want to call a function and get a result that you know already
exists (was previously already run and therefore memoized by
`AdlsPickleRunner`), you have two main options.

> ðŸš¨ In all cases, it's very important to understand that whether
> memoized results are or are not available within the namespace as
> provided or derived will _not_ prevent _new, unmemoized_ results
> from being computed. The function being called will have a
> namespace, and if a specific result cannot be found (has not
> previously been memoized), then the function will be run in the
> remote environment and its results will be 'inserted' into the
> namespace.
>
> In other words, no error will be raised if the result is
> not already present.
>
> This is a **non-destructive** re-use of the namespace, because no
> previous results will be modified in any way - but it _will_
> **modify** the existing namespace.

### pipeline id / global config

**By default**, a new pipeline id is generated in every orchestrator
  process, so results will not get reused by default.

Therefore, the global option is to set up your pipeline to run
identically to the run that generated the result. This includes
setting the `pipeline_id` to the same value as the known run, and
making sure that the [configured value](./config.md) for
`mops.memo.storage_root` is the same as from that known run.

This global option is most suitable for cases where your application
ran partway and then died for some reason. Re-using the same config
including `pipeline_id` will allow you to just pick up where you left
off.

### per-function (memospace) config

The more granular option is to configure, on a per-memoized/decorated
function basis, the `memospace` from the known run. You might choose
this approach if you have multiple memoized functions, and you only
want some of them to return an existing result (you wish the others to
run again, or to run with a different `pipeline_id`, or to store their
results in a different SA/container). You might also use it if the
function in question has been renamed and/or moved to a different
module since the results were memoized.

In the following example, function `foo` was previously run with
`pipeline_id=2023april`, and the results were stored on
`uaapdatascience/ml-ops`. The run which will re-use these results will
have an autogenerated `pipeline_id` and will use the configured values
for SA and container for all of the other, not-configured functions.

In a complete mops [config file](./config.md), add the following lines
to your config:

```toml
[mops.memo."thds.mymodule.foomod:foobar"]
memospace = "adls://uaapdatascience/ml-ops/mops/pipeline-pickled-functions-v1/2023april/thds.mymodule.foomod:foobar"
```

Note that the name that is part of the configuration key must be the
fully-qualified path to the function in the _current_ codebase. This
is how we will recognize what results you're trying to retrieve.

The `memospace`, however, is a fully-qualified ADLS URI that actually
exists and was created by the previous run that you're trying to
reuse. Note that to find this, you need to know three core components
from the previous run:

1. The URI that was configured as `mops.memo.storage_root`.
2. The `pipeline_id` that was in use.
3. The fully qualified `module:function_name` at the time of the run.

> âš ï¸ This configuration needs to be present every time a memoized result
> is retrieved. You cannot perform a new run with this config, and then
> expect a future reuse of the _new_ pipeline id to present you with
> those results. They will not be found.
>
> In other words, this configuration is cumulative and explicit - if
> you want to pick up results from various different historical runs,
> you'll need to specify the configuration for each previous run.
