link:../README.adoc[↑]

= Memoization/caching

A link:./pure_functions.adoc[pure function] is a fully-specified computation with a
deterministic result based on its arguments. If the function and its arguments remain the same, then a
future call to that function, even from a different process on a different computer, should be able to
return the previously-computed result rather than re-computing.

[sidebar]
One scenario where this might be useful would be in the case of some kind of
failure of your long-running orchestrator process. Another scenario would be the
architectural approach of sharing results that you know someone else has already computed.

NOTE: If you _aren't_ using the `pure.magic` API, a unique pipeline id is generated for
every application run, so no results will be memoized across processes. See
xref:#pipeline-id[pipeline id] for how to change this.

== Conceptual system in `mops`:

Each function using `mops` `MemoizingPicklingRunner` (a.k.a. link:magic.adoc[`@pure.magic`]) will combine:

* the current blob root
* the current `pipeline_id`
* the fully-qualfied name (including module) of the function
* the `function-logic-key` (if any)
* and the hash of the serialized arguments (input) to the function

to produce a _deterministic_ remote storage location for the invocation and also for the
eventual results.

[sidebar]
****
Why so many bits and pieces?

When you think about a function in the common sense, it's easy to forget that,
mathematically, a function isn't just a named bit of code - it's a *unique and immutable
transform*, of the input domain into the output codomain.

But in code, we change the code for functions (or the other functions they call) all the
time. We don't ordinarily rename the function afterward, but the actual effect of the
function has changed - technically it's a totally new function!

`mops` provides several different approaches to making it easier to map the mathematical
universe onto the everyday one that programmers inhabit. Perhaps _too many_ approaches -
they certainly overlap a bit at points. But collectively they provide a set of tools to
making your functions and their results a bit easier to wrangle, organize, and reason
about.
****

In its entirety, the unique invocation of your function with its arguments hash
constitutes the `memo_uri` - a `mops`-controlled namespace for the specific function under
the specific circumstances of its single invocation.

_Before_ invoking the function remotely, the `MemoizingPicklingRunner` will check to see if a result
already exists at the expected path, and if it does, that result will be returned _instead_ of running
the remote computation.

This allows function results to be reused across time regardless of who calls the function or when they
call it.

In cases where all you want is memoization (you don't care about transferring execution to
a truly link:./remote.adoc[remote execution environment]), you can use `@pure.magic()`
with no further customization.

In order to share results across machines, you'll want to configure at minimum the blob
root to point to a shared blob store.

The other bits and pieces and their purposes are documented below.

== Usage

At runtime, a fully-qualified `memo_uri` is derived from the following 'logical' components:

1. A blob root provided by your top-level configuration, plus a `mops`-specific suffix, making up a
   runner prefix that is the global default for any ``mops.pure``-wrapped function in your
   application. This is non-optional, but `pure.magic` sets the default as `$HOME/.mops-root`.

1. [[pipeline-id]] The `pipeline_id`.
  - `@pure.magic` sets a default pipeline id of `magic`.
  - Commonly, it may be set on a per-function basis by inserting the following annotation somewhere in
   the function docstring, like so:
+
[source,python]
----
@pure.use_runner(...)
def foobar():
   """some docs...
   pipeline-id: baz
   """
   ...
----
+
  - It may be masked via the `pure.pipeline_id_mask()` decorator/context manager,
    applied _over top of_ the `@pure.magic` or `@use_runner` decorators.
  - Each of the above will override a usage above it in the list.
+
You may conceptualize the pipeline id as representing a grouping namespace for multiple functions
within your application. A future version of `mops` may rename this concept to better communicate its
intended semantics.
+
NOTE: Often there is no reason to change the pipeline id, once defined. Used as a
grouping/naming mechanism, it's mostly a set-it-and-forget-it configuration.
+
1. A `function_id`, defined by derivation from the function's `__module__` + `__name__`.
+
This exists to keep identical `(*args, **kwargs)` separate from each other if passed to different
functions. There is no API for this; it's derived automatically.
+
WARNING: If you rename your function, all previous memoized results will no longer be
'found' for that function.

1. A `function-logic-key`, which is an _optional_ user-defined annotation. It will be automatically
   extracted when present from the docstring of the top-level function or any function passed as an
   argument (however nested) to the top-level function.
+
The intent of the `function-logic-key` is to allow you to annotate your function's logic as having
changed (and therefore invalidating previous memoization) without renaming your function (as, in
common software development practice, the name of a function is often a high-level name, not subject
to change every time the function is modified to produce different outputs).
+
[source,python]
----
@pure.use_runner(...)
def barbaz():
   """does some stuff.

   function-logic-key: 241024-v2
   """
   ...
----
+
Function logic keys MUST NOT contain spaces - any whitespace character will be interpreted as the end
of the key.
+
A function may have both a `pipeline-id` and `function-logic-key` annotation in its
docstring. The order does not matter, but each should be on a separate line.

### Memospace parts

This is an example full `memo_uri` with all its constituent parts labeled. You'll find most of these
names directly link:../src/thds/mops/pure/core/memo/function_memospace.py[in the source code]. For
memoization to retrieve an existing result, the _full_ constructed memo uri must be retrievable from the
provided storage system.

[%nowrap,source,text]
----
adls://thdsscratch/tmp/mops2-mpf/Peter-Gaultney/2023-04-12T15:46:24-p36529/demandforecast.extract:extract_asset_geo_level/CoastOilAsset.IVZ9KplQKlNgxQHav0jIMUS9p4Kbn3N481e0Uvs/
<blob root ---------->
<runner prefix ----------------> <pipeline_id ---------------------------> <function_id --------------------------------> <(args, kwargs) sha256 hash ------------------------>
<pipeline memospace ----------------------------------------------------->
<function memospace ---------------------------------------------------------------------------------------------------->
                                 <invocation-unique-key ---------------------------------------------------------------------------------------------------------------------->
<memo uri -------------------------------------------------------------------------------------------------------------------------------------------------------------------->
----

Note that the `invocation-unique-key` is a way of uniquely identifying a function invocation solely by
reference to the user-controllable, storage-agnostic elements of the `memo_uri`.

## Advanced Usage

In general, the blob root and pipeline id should be encoded either in your code (often
preferable and less 'spooky') or in some kind of config that gets loaded into your code at
runtime. So the information above is mostly about 'understanding what they do.'

However, if you want to call a function and get a result that you know already exists (was previously already run
and therefore memoized by `MemoizingPicklingRunner`), you have three main options. These options are
listed in reverse priority order - the more specific options (listed further down) will be checked first,
and if configured, the less-specific options (listed earlier) will not be attempted.

[WARNING]
====
Whether or not memoized results are available within the namespace as specified or derived
will _not_ prevent _new, unmemoized_ results from being computed and inserted into that
same namespace.

In other words, no error will be raised if the result is not already present. This is a
**non-destructive** re-use of the namespace, because no existing results will be modified in any way -
but an existing namespace is never immune to **modification** if provided to `mops`.
====

### Configure: pipeline id mask with global blob root

[sidebar]
Scope: global blob root, plus stack-local pipeline id mask set by the application or library via
decorator or context manager.

You may decorate any `use_runner`-decorated function with `thds.mops.pure.pipeline_id_mask`. It _must_ be
applied outside the `use_runner` decorator, because it will set a stack-local variable at the time of
invocation of the function, but prior to the operation of the underlying `Runner` that will reference its
work.

NOTE: A pipeline id mask will in all cases override the global pipeline id.

It may also be used as a context manager, with the caveat that this will _not_ propagate to threads
created in the current context.

[WARNING]
====
☠️ ☠️ ☠️ Logically, the 'pipeline id mask' for a given function changes every time the function code
changes. If you use this as a decorator directly on a `use_runner` function, and fail to change its
string value after the underlying code has changed, then your function's callers will get **unwanted**
memoization. **YOU HAVE BEEN WARNED.**
====

[source,python]
----
# every call to this function will automatically use the below pipeline_id.
# The decorator will always apply regardless of threading.

@pipeline_id_mask('2023-05-02')
@use_runner(MemoizingPicklingRunner(...))
def generate_nppes(...):
    ...

@pipeline_id_mask('other')
@use_runner(MemoizingPicklingRunner(...))
def use_nppes(...):
    ...

# however, if a caller wishes to override, they have several options:

# option 1, as context manager
# suitable for call only in the _current_ thread/process:
with pipeline_id_mask('special-run'):
    nppes = generate_nppes(...)
    use_nppes(nppes)
    # note that both mops functions will use this same pipeline id mask.

# option 2, suitable for calling the function in a separate thread later on...
my_special_nppes = pipeline_id_mask('special-run')(generate_nppes)
...
nppes = my_special_nppes(...)
# but the undecorated `use_nppes` will use its own mask
use_nppes(nppes)

# option 3, also suitable for use in a launched thread:
@pipeline_id_mask('special-run')
def my_special_nppes(*args, **kwargs):
    args, kwargs = special_adjust_args_kwargs(args, kwargs)
    return generate_nppes(*args, **kwargs)
...
my_special_nppes(...)
----

As seen above, this decorator or its underlying context manager may even be applied multiple times -
_only_ the outermost call to this decorator will be applied at the time of function invocation, providing
the final say to the calling application.

### Configure: pipeline memospace with dynamic runtime matching

[sidebar]
Scope: match a function or set of functions based on their fully-qualified `+__module__:__name__+`
using Python code registered as one of many in-order globally-registered handlers

This is probably most appropriate for applications that wish to provide control over the pipeline id or
overall pipeline memospace for their functions but only their functions; in other words, for applications
that do _not_ wish to override the choices of other libraries using mops from which they consume outputs.

A simple example would be something like the following:

[source,python]
----
# in module `thds.bar.where.ever`

@pure.use_runner(...)
def thing1(...):
    """pipeline-id: BAR-STANDARD"""
    ...

# in module `thds.foo.stuff`
@pure.use_runner(...)
def thing2(...):
    """pipeline-id: FOO-STANDARD"""
    ...

# in module `thds.foo.main`
pure.add_pipeline_memospace_handlers(
    pure.matching_mask_pipeline_id('FOO-NON-STANDARD!!', r'thds\.foo')
)
----

The above will mask the pipeline id for `thing2` in `thds.foo.stuff` (as well as any other functions
underneath `thds.foo`) but will _not_ mask the pipeline id for `thds.bar.where.ever:thing1`, as its
fully-qualified name will not match the `thds.foo` regex.

NOTE: This _overrides_ the use of `pipeline_id_mask` in all respects if a match is found. It is up to the
application developers to have their handler respect existing ``pipeline_id_mask``s if they so choose.

### Configure: function-scoped fully-qualified memospace

[sidebar]
Scope: per-function (referenced by function_id) memospace, set by application via global (TOML) or
stack-local (context manager) config.

The most direct option is to configure, on a per-memoized/decorated function basis, the fully-qualified
`memospace` from the known run, referenced by the fully-qualified name of the function at its _current
location_.

NOTE: This approach overrides **both** of the previous approaches, and differs from them in that any
globally-configured blob root will be overridden by this fully-qualified function memospace.

You might use this option if the function in question has been renamed and/or moved to a different module
since the results were memoized, or if you know an exact location where previous results exist and you
want to hard-code that result set outside of your code. This renaming ability affords the most direct
control compared to the other options for configuring memoization.

In the following example, function `foo` was previously run with `pipeline_id=2023april`, and the results
were stored on `adls://thdsdata/ml-ops`. The run which will re-use these results will have an
autogenerated `pipeline_id` and will use the configured values for SA and container for all of the other,
not-configured functions.

In a mops link:./config.adoc[config file], add the following lines to your config:

[source,toml]
----
[mops.memo."thds.mymodule.foomod:foobar"]
memospace = "adls://thdsdata/ml-ops/mops/pipeline-pickled-functions-v1/2023april/thds.mymodule.OLDMOD:barbaz"
----

Note that the name that is part of the configuration key must be the fully-qualified path to the function
in the _current_ codebase. This is how we will recognize what results you're trying to retrieve when you
call the current function.

The `memospace`, however, is a fully-qualified ADLS URI that actually exists and was created by the
previous run that you're trying to reuse. Note that to find this, you need to know three core components
from the previous run:

1. The URI that was configured as `mops.pure.magic.blob_root`.
1. The `pipeline_id` that was in use.
1. The fully qualified `module:function_name@function-logic-key` at the time of the run.

[WARNING]
====
This configuration needs to be present every time a memoized result is retrieved. You cannot perform
a new run with this config, and then expect a future reuse of the _new_ pipeline id to present you with
those results. They will not be found.

In other words, this configuration is cumulative and explicit - if you want to pick up results from
various different historical runs, you'll need to specify the configuration for each previous run.
====
