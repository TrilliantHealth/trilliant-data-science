link:../README.adoc[↑]

# Memoization/caching

A link:./pure_functions.adoc[pure function] is by definition a fully-specified computation with a
deterministic result based on its arguments. If the function and its arguments remain the same, then a
future call to that function, even from a different process on a different computer, should be able to
return the previously-computed result rather than re-computing.

One scenario where this might be useful would be in the case of some kind of failure of your long-running
orchestrator process. Another scenario would be the architectural approach of sharing results that you
know someone else has already computed.

NOTE: By default, a unique pipeline id is generated for every application run, so no results
will be memoized across processes. See xref:#pipeline-id[pipeline id] for how to change this.

## Conceptual system in `mops`:

Each `use_runner`-decorated function using `mops` `MemoizingPicklingRunner` will combine the
current `pipeline_id`, the fully-qualfied name (including module) of the function, and the hash of
the serialized arguments to the function, to produce a _deterministic_ remote storage location for the
invocation and also for the eventual results.

In its entirety, the unique invocation of your function with its arguments hash constitutes the
`memo_uri` - a namespace for your specific function under the specific circumstances of its single
invocation.

_Before_ invoking the function remotely, the `MemoizingPicklingRunner` will check to see if a result
already exists at the expected path, and if it does, that result will be returned _instead_ of running
the remote computation.

This allows function results to be reused across time regardless of who calls the function or when they
call it.

In cases where all you want is memoization (you don't care about transferring execution to a truly
link:./remote.adoc[remote execution environment]), you may be able to use `pure.memoize_in` as a shorthand,
rather than needing to define a `MemoizingPicklingRunner` yourself.

In link:./advanced_memoization.adoc[advanced use cases], you may want to memoize on something other than the
actual function arguments.

## Usage

In implementation, a fully-qualified `memo_uri` is derived from the following 'logical' components:

1. A storage root provided by your top-level configuration, plus a `mops`-specific suffix, making up a
   runner prefix that is the global default for any `pure.use_runner` decorated function in your
   application.

1. [[pipeline-id]] The `pipeline_id`.
  - It can be set globally by the application using `pure.set_pipeline_id()`
  - It may also be masked via the `pure.pipeline_id_mask()` decorator/context manager, applied _over top of_ the `use_runner` decorator.
  - Most commonly, it may be set on a per-function basis by inserting the following annotation somewhere in
   the function docstring, like so:
+
[source,python]
----
@pure.use_runner(...)
def foobar():
   """some docs...
   pipeline-id-mask: baz
   """
   ...
----
+
You may conceptualize the pipeline id as representing a grouping namespace for multiple functions
within your application. A future version of `mops` may rename this concept to better communicate its
intended semantics.
+
Often there is no reason to change the pipeline id, once defined.

1. A `function_id`, defined by derivation from the function's `__module__` + `__name__`.
+
This exists to keep identical `(*args, **kwargs)` separate from each other if passed to different
functions.
+
NOTE: If you rename your function, all previous memoized results will no longer be
'found' for that function.

1. A `function-logic-key`, which is an _optional_ user-defined annotation. It will be automatically
   extracted when present from the docstring of the top-level function or any function passed as an
   argument (however nested) to the top-level function.
+
The intent of the `function-logic-key` is to allow you to annotate your function's logic as having
changed (and therefore invalidating previous memoization) without renaming your function (as, in
common software development practice, the name of a function is often a high-level name, not subject
to change every time its outputs change).
+
[source,python]
----
@pure.use_runner(...)
def barbaz():
   """does some stuff.

   function-logic-key: 2024-10-24-v2
   """
   ...
----
+
Function logic keys MUST NOT contain spaces - any whitespace character will be interpreted as the end
of the key.
+
A function may have both a `pipeline-id-mask` and `function-logic-key` annotation in its docstring.

The function author is fully (and trivially) in control of the `function_id` and `function-logic-key`
components, but the application that calls the function is encouraged to globally set and/or locally mask
the `pipeline id`. Generally, the `storage root` will be set differently via configuration for production
vs development, but will be shared across the application run.

### Memospace parts

This is an example full `memo_uri` with all its constituent parts labeled. You'll find most of these
names directly link:../src/thds/mops/pure/core/memo/function_memospace.py[in the source code]. For
memoization to retrieve an existing result, the _full_ constructed memo uri must be retrievable from the
provided storage system.

[%nowrap,source,text]
----
adls://thdsscratch/tmp/mops2-mpf/Peter-Gaultney/2023-04-12T15:46:24-p36529/demandforecast.extract:extract_asset_geo_level/CoastOilAsset.IVZ9KplQKlNgxQHav0jIMUS9p4Kbn3N481e0Uvs/
<storage root ------->
<runner prefix ----------------> <pipeline_id ---------------------------> <function_id --------------------------------> <(args, kwargs) sha256 hash ------------------------>
<pipeline memospace ----------------------------------------------------->
<function memospace ---------------------------------------------------------------------------------------------------->
                                <invocation-unique-key ----------------------------------------------------------------------------------------------------------------------->
<memo uri -------------------------------------------------------------------------------------------------------------------------------------------------------------------->
----

Note that the `invocation-unique-key` is a way of uniquely identifying a function invocation solely by
reference to the user-controllable, storage-agnostic elements of the `memo_uri`.

Therefore:

If you want to call a function and get a result that you know already exists (was previously already run
and therefore memoized by `MemoizingPicklingRunner`), you have three main options. These options are
listed in reverse priority order - the more specific options (listed further down) will be checked first,
and if configured, the less-specific options (listed earlier) will not be attempted.

[WARNING]
====
Whether or not memoized results are available within the namespace as specified or derived
will _not_ prevent _new, unmemoized_ results from being computed and inserted into that
same namespace.

In other words, no error will be raised if the result is not already present. This is a
**non-destructive** re-use of the namespace, because no existing results will be modified in any way -
but an existing namespace is never immune to **modification** if provided to `mops`.
====

### Configure: global pipeline id with global storage root

[sidebar]
Scope: global, via dict config or set globally by the application.

The global option is to set up your application to run identically to the run that generated the result.
This includes making sure that the link:./config.adoc[configured value] for `mops.memo.storage_root` is the
same as from that known run, and then calling `set_pipeline_id` with the `pipeline_id` used or generated
by the known run.

This global option is most suitable for cases where your application ran partway and then died for some
reason. Re-using the same config including `pipeline_id` will allow you to just pick up where you left
off.

The simplest way to set the global pipeline id is by calling
`thds.mops.pure:set_pipeline_id('yourpipeid')` in the CLI of your application. Be aware that this is a
global call that must be performed before calling any `mops`-decorated functions.

### Configure: pipeline id mask with global storage root

[sidebar]
Scope: global storage root, plus stack-local pipeline id mask set by the application or library via
decorator or context manager.

You may decorate any `use_runner`-decorated function with `thds.mops.pure.pipeline_id_mask`. It _must_ be
applied outside the `use_runner` decorator, because it will set a stack-local variable at the time of
invocation of the function, but prior to the operation of the underlying `Runner` that will reference its
work.

NOTE: A pipeline id mask will in all cases override the global pipeline id.

It may also be used as a context manager, with the caveat that this will _not_ propagate to threads
created in the current context.

[WARNING]
====
☠️ ☠️ ☠️ Logically, the 'pipeline id mask' for a given function changes every time the function code
changes. If you use this as a decorator directly on a `use_runner` function, and fail to change its
string value after the underlying code has changed, then your function's callers will get **unwanted**
memoization. **YOU HAVE BEEN WARNED.**
====

[source,python]
----
# every call to this function will automatically use the below pipeline_id.
# The decorator will always apply regardless of threading.

@pipeline_id_mask('2023-05-02')
@use_runner(MemoizingPicklingRunner(...))
def generate_nppes(...):
    ...

@pipeline_id_mask('other')
@use_runner(MemoizingPicklingRunner(...))
def use_nppes(...):
    ...

# however, if a caller wishes to override, they have several options:

# option 1, as context manager
# suitable for call only in the _current_ thread/process:
with pipeline_id_mask('special-run'):
    nppes = generate_nppes(...)
    use_nppes(nppes)
    # note that both mops functions will use this same pipeline id mask.

# option 2, suitable for calling the function in a separate thread later on...
my_special_nppes = pipeline_id_mask('special-run')(generate_nppes)
...
nppes = my_special_nppes(...)
# but the undecorated `use_nppes` will use its own mask
use_nppes(nppes)

# option 3, also suitable for use in a launched thread:
@pipeline_id_mask('special-run')
def my_special_nppes(*args, **kwargs):
    args, kwargs = special_adjust_args_kwargs(args, kwargs)
    return generate_nppes(*args, **kwargs)
...
my_special_nppes(...)
----

As seen above, this decorator or its underlying context manager may even be applied multiple times -
_only_ the outermost call to this decorator will be applied at the time of function invocation, providing
the final say to the calling application.

### Configure: pipeline memospace with dynamic runtime matching

[sidebar]
Scope: match a function or set of functions based on their fully-qualified `+__module__:__name__+`
using Python code registered as one of many in-order globally-registered handlers

This is probably most appropriate for applications that wish to provide control over the pipeline id or
overall pipeline memospace for their functions but only their functions; in other words, for applications
that do _not_ wish to override the choices of other libraries using mops from which they consume outputs.

A simple example would be something like the following:

[source,python]
----
# in module `thds.bar.where.ever`

@pure.use_runner(...)
def thing1(...):
    """pipeline-id-mask: BAR-STANDARD"""
    ...

# in module `thds.foo.stuff`
@pure.use_runner(...)
def thing2(...):
    """pipeline-id-mask: FOO-STANDARD"""
    ...

# in module `thds.foo.main`
pure.add_pipeline_memospace_handlers(
    pure.matching_mask_pipeline_id('FOO-NON-STANDARD!!', r'thds\.foo')
)
----

The above will mask the pipeline id for `thing2` in `thds.foo.stuff` (as well as any other functions
underneath `thds.foo`) but will _not_ mask the pipeline id for `thds.bar.where.ever:thing1`, as its
fully-qualified name will not match the `thds.foo` regex.

NOTE: This _overrides_ the use of `pipeline_id_mask` in all respects if a match is found. It is up to the
application developers to have their handler respect existing ``pipeline_id_mask``s if they so choose.

### Configure: function-scoped fully-qualified memospace

[sidebar]
Scope: per-function (referenced by function_id) memospace, set by application via global (TOML) or
stack-local (context manager) config.

The most direct option is to configure, on a per-memoized/decorated function basis, the fully-qualified
`memospace` from the known run, referenced by the fully-qualified name of the function at its _current
location_.

NOTE: This approach overrides **both** of the previous approaches, and differs from them in that any
globally-configured storage root will be overridden by this fully-qualified function memospace.

You might use this option if the function in question has been renamed and/or moved to a different module
since the results were memoized, or if you know an exact location where previous results exist and you
want to hard-code that result set outside of your code. This renaming ability affords the most direct
control compared to the other options for configuring memoization.

In the following example, function `foo` was previously run with `pipeline_id=2023april`, and the results
were stored on `adls://thdsdata/ml-ops`. The run which will re-use these results will have an
autogenerated `pipeline_id` and will use the configured values for SA and container for all of the other,
not-configured functions.

In a mops link:./config.adoc[config file], add the following lines to your config:

[source,toml]
----
[mops.memo."thds.mymodule.foomod:foobar"]
memospace = "adls://thdsdata/ml-ops/mops/pipeline-pickled-functions-v1/2023april/thds.mymodule.OLDMOD:barbaz"
----

Note that the name that is part of the configuration key must be the fully-qualified path to the function
in the _current_ codebase. This is how we will recognize what results you're trying to retrieve when you
call the current function.

The `memospace`, however, is a fully-qualified ADLS URI that actually exists and was created by the
previous run that you're trying to reuse. Note that to find this, you need to know three core components
from the previous run:

1. The URI that was configured as `mops.memo.storage_root`.
1. The `pipeline_id` that was in use.
1. The fully qualified `module:function_name` at the time of the run.

[WARNING]
====
This configuration needs to be present every time a memoized result is retrieved. You cannot perform
a new run with this config, and then expect a future reuse of the _new_ pipeline id to present you with
those results. They will not be found.

In other words, this configuration is cumulative and explicit - if you want to pick up results from
various different historical runs, you'll need to specify the configuration for each previous run.
====
