"""Utilities built around pickle for the purpose of transferring large amounts of on-disk
data and also functions."""

import io
import os
import pickle
import typing as ty
from functools import partial

# so we can pickle and re-raise exceptions with remote tracebacks
from tblib import pickling_support  # type: ignore

from thds.core import hashing, inspect, log, source

from ..core import memo, metadata
from ..core.source import prepare_source_argument, prepare_source_result
from ..core.types import Args, Deserializer, Kwargs, SerializerHandler
from ..core.uris import get_bytes
from .pickles import (
    PicklableFunction,
    UnpickleFunctionWithLogicKey,
    UnpickleSourceHashrefArgument,
    UnpickleSourceResult,
    UnpickleSourceUriArgument,
)

logger = log.getLogger(__name__)
F = ty.TypeVar("F", bound=ty.Callable)


def wrap_f(f: F) -> ty.Union[F, PicklableFunction]:
    if hasattr(f, "__module__") and hasattr(f, "__name__"):
        return PicklableFunction(f)
    return f


class _CallbackPickler(pickle.Pickler):
    def __init__(self, handlers: ty.Sequence[SerializerHandler], *args: ty.Any, **kwargs: ty.Any):
        super().__init__(*args, **kwargs)
        self.handlers = handlers

    def persistent_id(self, obj: ty.Any) -> ty.Union[None, ty.Callable]:
        if isinstance(obj, Exception):
            pickling_support.install(obj)
        for handler in self.handlers:
            pid = handler(obj)
            if pid is not None:
                return pid
        return None


class CallableUnpickler(pickle.Unpickler):
    """Present same interface as pickle.load but support unpickling callable PIDs generated by CallbackPickler."""

    def persistent_load(self, pid: ty.Callable) -> ty.Any:
        try:
            return pid()
        except TypeError as te:
            # logger.exception("TypeError hit while debugging")
            # this line should never get hit as long as nobody asks us to unpickle PIDs we don't know about
            raise pickle.UnpicklingError(f"unsupported persistent object - {te}")  # pragma: no cover


class Dumper:
    """Presents the same interface as pickle.dump but supports
    arbitrary callback-based unpickling.
    """

    def __init__(self, *handlers: SerializerHandler):
        self.handlers = handlers

    def __call__(self, obj: object, file: ty.IO, *args: ty.Any, **kwargs: ty.Any) -> ty.Any:
        _CallbackPickler(self.handlers, file, *args, **kwargs).dump(obj)


def gimme_bytes(pickle_dump: ty.Callable[[object, ty.IO], None], obj: object) -> bytes:
    with io.BytesIO() as bio:
        pickle_dump(obj, bio)
        bio.seek(0)
        return bio.read()


def read_partial_pickle(full_bytes: bytes) -> ty.Tuple[bytes, bytes]:
    # in order to be forward-compatible with v3 of mops, we're introducing a new
    # wrinkle in the read. Instead of assuming that the data at the URI
    # _begins_ with a pickle, we are looking for the first possible pickle
    # and beginning our read there. Mops 3 will be generating some human-readable,
    # non-pickle metadata and embedding it at the beginning of the file.
    first_pickle_pos = full_bytes.find(b"\x80")
    if first_pickle_pos == -1:
        raise ValueError(f"Unable to find a pickle in bytes of length {len(full_bytes)}")
    return full_bytes[:first_pickle_pos], full_bytes[first_pickle_pos:]


def _unpickle_with_callable(pickle_bytes: bytes) -> ty.Any:
    return CallableUnpickler(io.BytesIO(pickle_bytes)).load()


H = ty.TypeVar("H")


def make_read_header_and_object(
    type_hint: str, xf_header: ty.Optional[ty.Callable[[bytes], H]] = None
) -> ty.Callable[[str], ty.Tuple[H, ty.Any]]:
    def read_object(uri: str) -> ty.Tuple[H, ty.Any]:
        uri_bytes = get_bytes(uri, type_hint=type_hint)
        if not uri_bytes:
            raise ValueError(f"{uri} exists but is empty - something is very wrong.")
        header, first_pickle = read_partial_pickle(uri_bytes)
        return (xf_header or (lambda h: h))(header), _unpickle_with_callable(first_pickle)  # type: ignore

    return read_object


def read_metadata_and_object(
    type_hint: str, uri: str
) -> ty.Tuple[ty.Optional[metadata.ResultMetadata], ty.Any]:
    def _read_metadata_header(header_bytes: bytes) -> ty.Optional[metadata.ResultMetadata]:
        if not header_bytes:
            return None
        return metadata.parse_result_metadata(header_bytes.decode("utf-8").split("\n"))

    return make_read_header_and_object(type_hint, xf_header=_read_metadata_header)(uri)


def freeze_args_kwargs(dumper: Dumper, f: ty.Callable, args: Args, kwargs: Kwargs) -> bytes:
    """Returns a pickled (args, kwargs) tuple, with pre-bound
    arguments to normalize different call structures into a
    canonical/determinstic binding.

    Also binds default arguments, for maximum determinism/explicitness.
    """
    bound_arguments = inspect.bind_arguments(f, *args, **kwargs)
    return gimme_bytes(dumper, (bound_arguments.args, bound_arguments.kwargs))


def unfreeze_args_kwargs(
    args_kwargs_pickle: bytes, unpickler: ty.Type[pickle.Unpickler] = CallableUnpickler
) -> ty.Tuple[Args, Kwargs]:
    """Undoes a freeze_args_kwargs call."""
    return unpickler(io.BytesIO(args_kwargs_pickle)).load()


# SerializerHandlers for Source objects:
_DeserSource = ty.Callable[[], source.Source]


class SourceArgumentPickler:
    """Only for use on the orchestrator side, when serializing the arguments."""

    def __call__(self, maybe_source: ty.Any) -> ty.Optional[_DeserSource]:
        if isinstance(maybe_source, source.Source):
            uri_or_hash = prepare_source_argument(maybe_source)
            if isinstance(uri_or_hash, hashing.Hash):
                return ty.cast(_DeserSource, UnpickleSourceHashrefArgument(uri_or_hash))
            return ty.cast(_DeserSource, UnpickleSourceUriArgument(uri_or_hash))
            # I do not understand why these casts are necessary to avoid mypy errors.
            # I think it has something to do with NamedTuples being the underlying
            # object type that is expected to support __call__(self) -> Foo,
            # but I haven't recently located a relevant Issue anywhere.
        return None


class DuplicateSourceBasenameError(ValueError):
    pass


class SourceResultPickler:
    """Only for use on the remote side, when serializing the result."""

    def __init__(self) -> None:
        """There will be one of these per remote function call."""
        self._basenames_seen: set[str] = set()

    def __call__(self, maybe_source: ty.Any) -> ty.Optional[_DeserSource]:
        if isinstance(maybe_source, source.Source):
            src_res = prepare_source_result(maybe_source)
            if src_res.file_uri:
                # we need to check to make sure that this file_uri is not a duplicate
                # - if it is, this indicates that this single function is attempting to return
                # two Source objects that have not yet been uploaded but will be uploaded to the same name.
                file_basename = os.path.basename(src_res.file_uri)
                if file_basename in self._basenames_seen:
                    raise DuplicateSourceBasenameError(
                        f"Duplicate basename {os.path.basename(src_res.file_uri)} found in SourceResultPickler."
                        " This is usually an indication that you have two files with the same name in two different directories,"
                        " and are trying to convert them into Source objects with automatically-assigned URIs."
                        " Per the documentation, all output Source objects without explicitly assigned remote URIs must be provided"
                        " with unique basenames, in order to allow retention of the basename for usability and debugging."
                    )
                self._basenames_seen.add(file_basename)
            return ty.cast(_DeserSource, UnpickleSourceResult(*src_res))

        return None


class NestedFunctionWithLogicKeyPickler:
    def __call__(self, maybe_function_with_logic_key: ty.Any) -> ty.Optional[Deserializer]:
        """Returns a pickle 'persistent id' which is a 'kind' of CallableUnpickler.

        ...or None, which means pickle normally.
        """
        if not callable(maybe_function_with_logic_key):
            return None

        if isinstance(maybe_function_with_logic_key, partial):
            # do not extract from the partial - only a raw function
            # which will itself be included in the partial when it gets pickled
            return None

        function_logic_key = memo.extract_function_logic_key_from_docstr(maybe_function_with_logic_key)
        if not function_logic_key:
            return None

        return UnpickleFunctionWithLogicKey(  # type: ignore
            # we must then wrap the function itself so that this does not cause infinite recursion.
            pickle.dumps(maybe_function_with_logic_key),
            function_logic_key,
        )
